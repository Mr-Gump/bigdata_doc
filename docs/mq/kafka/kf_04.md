# 第4章 Kafka Broker

## 4.1 Kafka Broker工作流程

#### 4.1.1 Zookeeper存储的Kafka信息

（1）启动 Zookeeper 客户端。

```shell
bin/zkCli.sh
```

（2）通过 ls 命令可以查看 Kafka 相关信息。

```shell
[zk: localhost:2181(CONNECTED) 2] ls /kafka
```

![image-20230207194114087](https://cos.gump.cloud/uPic/image-20230207194114087.png)

### 4.1.2 Kafka Broker总体工作流程

![image-20230207194250528](https://cos.gump.cloud/uPic/image-20230207194250528.png)

1）模拟 Kafka 上下线，Zookeeper 中数据变化

​	（1）查看 /kafka/brokers/ids 路径上的节点。

```shell
[zk: localhost:2181(CONNECTED) 2] ls /kafka/brokers/ids
```

​	（2）查看 /kafka/controller 路径上的数据。

```shell
[zk: localhost:2181(CONNECTED) 15] get /kafka/controller
```

​	（3）查看 /kafka/brokers/topics/first/partitions/0/state 路径上的数据。

```shell
[zk: localhost:2181(CONNECTED) 16] get /kafka/brokers/topics/first/partitions/0/state
```

（4）停止 hadoop104 上的 Kafka。

```shell
bin/kafka-server-stop.sh
```

（5）再次查看 /kafka/brokers/ids 路径上的节点。

```shell
[zk: localhost:2181(CONNECTED) 3] ls /kafka/brokers/ids
```

（6）再次查看 /kafka/controller 路径上的数据。

```shell
[zk: localhost:2181(CONNECTED) 15] get /kafka/controller
```

（7）再次查看 /kafka/brokers/topics/first/partitions/0/state 路径上的数据。

```shell
[zk: localhost:2181(CONNECTED) 16] get /kafka/brokers/topics/first/partitions/0/state
```

（8）启动 hadoop104 上的 Kafka。
```shell
bin/kafka-server-start.sh -daemon ./config/server.properties
```

（9）再次观察（1）、（2）、（3）步骤中的内容。

### 4.1.3 Broker重要参数

| 参数名称                                | 描述                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| replica.lag.time.max.ms                 | ISR 中，如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值，默认 {==30s==}。 |
| auto.leader.rebalance.enable            | 默认是 {==true==}。 自动 Leader Partition 平衡。             |
| leader.imbalance.per.broker.percentage  | 默认是 {==10%==}。每个 broker 允许的不平衡的 leader 的比率。如果每个 broker 超过了这个值，控制器会触发 leader 的平衡。 |
| leader.imbalance.check.interval.seconds | 默认值 {==300 秒==}。检查 leader 负载是否平衡的间隔时间。    |
| log.segment.bytes                       | Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分成块的大小，默认值 {==1G==}。 |
| log.index.interval.bytes                | 默认 {==4kb==}，Kafka 里面每当写入了 4kb 大小的日志（.log），然后就往 index 文件里面记录一个索引。 |
| log.retention.hours                     | Kafka 中数据保存的时间，默认 {==7天==}。                     |
| log.retention.minutes                   | Kafka 中数据保存的时间，分钟级别，默认关闭。                 |
| log.retention.ms                        | Kafka 中数据保存的时间，毫秒级别，默认关闭。                 |
| log.retention.check.interval.ms         | 检查数据是否保存超时的间隔，默认是 {==5 分钟==}。            |
| log.retention.bytes                     | {==默认等于 -1，表示无穷大==}。超过设置的所有日志总大小，删除最早的 segment。 |
| log.cleanup.policy                      | 默认是 {==delete==}，表示所有数据启用删除策略；如果设置值为 compact，表示所有数据启用压缩策略。 |
| num.io.threads                          | 默认是 {==8==}。负责写磁盘的线程数。这个参数值要占{==总核数的 50%==}。 |
| num.replica.fetchers                    | 副本拉取线程数，这个参数占总核数的 50% 的 1/3                |
| num.network.threads                     | 默认是 3。数据传输线程数，这个参数占总核数的 50% 的 2/3 。   |
| log.flush.interval.messages             | 强制页缓存刷写到磁盘的条数，默认是 {==long 的最大值==}，9223372036854775807。一般不建议修改，交给系统自己管理。 |
| log.flush.interval.ms                   | 每隔多久，刷数据到磁盘，默认是 null。一般不建议修改，交给系统自己管理。 |

## 4.2 Kafka 副本

### 4.2.1 副本基本信息

（1）Kafka 副本作用：{++提高数据可靠性++}。

（2）Kafka 默认副本 1 个，生产环境一般配置为 2 个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。

（3）Kafka 中副本分为：Leader 和 Follower。Kafka 生产者只会把数据发往 Leader，然后 Follower 找 Leader 进行同步数据。

（4）Kafka 分区中的所有副本统称为 AR（Assigned Repllicas）。
$$
AR = ISR + OSR
$$

- ISR：表示和 Leader 保持同步的 Follower 和 Leader 集合。如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 replica.lag.time.max.ms 参数设定，默认 30s。Leader 发生故障之后，就会从 ISR 中选举新的 Leader。
- OSR：表示 Follower 与 Leader 副本同步时，延迟过多的副本。

### 4.2.2 Leader选举流程

Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller  Leader，负责{++管理集群 broker 的上下线++}，{++所有 topic 的分区副本分配++}和 {++Leader 选举++}等工作。

Controller 的信息同步工作是依赖于 Zookeeper 的。

![image-20230207195805315](https://cos.gump.cloud/uPic/image-20230207195805315.png)

假设有 hadoop102、hadoop103、hadoop104、hadoop105 等 4 台服务器。

（1）创建一个新的 topic，4 个分区，4 个副本

```shell
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --topic atguigu1 --partitions 4 --replication-factor 4
```

（2）查看 Leader 分布情况

```shell
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1
```

（3）停止掉 hadoop105 的 Kafka 进程，并查看 Leader 分区情况

```shell
bin/kafka-server-stop.sh
```

（4）停止掉 hadoop104 的 Kafka 进程，并查看 Leader 分区情况

```shell
bin/kafka-server-stop.sh
```

（5）启动 hadoop105 的 Kafka 进程，并查看 Leader 分区情况

```shel
bin/kafka-server-start.sh -daemon config/server.properties
```

（6）启动 hadoop104 的 Kafka 进程，并查看 Leader 分区情况

```shell
bin/kafka-server-start.sh -daemon config/server.properties
```

（7）停止掉 hadoop103 的 Kafka 进程，并查看 Leader 分区情况

```shell
bin/kafka-server-stop.sh
```

### 4.2.3 Leader和Follower故障处理细节

![image-20230207200308307](https://cos.gump.cloud/uPic/image-20230207200308307.png)

![image-20230207200321556](https://cos.gump.cloud/uPic/image-20230207200321556.png)

## 4.3 文件存储

### 4.3.1 文件存储机制

1）Topic 数据的存储机制

![image-20230207200607005](https://cos.gump.cloud/uPic/image-20230207200607005.png)

!!! question "思考"

    Topic 数据到底存储在什么位置？

（1）启动生产者，并发送消息。

```shell
bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first
```

（2）查看 hadoop102（或者 hadoop103、hadoop104 ）的 /opt/module/kafka/datas/first-1（first-0、first-2）路径上的文件。

<div class="termy">
```console
$ ls

00000000000000000092.index
00000000000000000092.log
00000000000000000092.snapshot
00000000000000000092.timeindex
leader-epoch-checkpoint
partition.metadata
```
</div>


（3）直接查看 log 日志，发现是乱码。

（4）通过工具查看 index 和 log 信息。

```shell
kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.index 
  ```

3）index 文件和 log 文件详解

![image-20230207201000939](https://cos.gump.cloud/uPic/image-20230207201000939.png)

说明：日志存储参数配置

| 参数                     | 描述                                                         |
| ------------------------ | ------------------------------------------------------------ |
| log.segment.bytes        | Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。 |
| log.index.interval.bytes | 默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。 稀疏索引。 |

### 4.3.2 文件清理策略

Kafka 中{==默认的日志保存时间为 7 天==}，可以通过调整如下参数修改保存时间。

+ `log.retention.hours`：最低优先级小时，默认 7 天。
+ `log.retention.minutes`：分钟
+ `log.retention.ms`：最高优先级毫秒
+ `log.retention.check.interval.ms`：负责设置检查周期，默认5分钟

!!! question 

    那么日志一旦超过了设置的时间，怎么处理呢？

Kafka 中提供的日志清理策略有 {++delete++} 和 {++compact++} 两种。

1）delete 日志删除：将过期数据删除

`log.cleanup.policy = delete`    所有数据启用删除策略

（1）基于时间：{==默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳==}。

（2）基于大小：{==默认关闭==}。超过设置的所有日志总大小，删除最早的 segment。

`log.retention.bytes` 默认等于 -1，表示无穷大。

!!! question "思考"

    如果一个 segment 中有一部分数据过期，一部分没有过期，怎么处理？

2）compact 日志压缩

![image-20230207201601807](https://cos.gump.cloud/uPic/image-20230207201601807.png)

## 4.4 高效读写数据

1）Kafka 本身是分布式集群，可以采用{==分区技术==}，并行度高

2）读数据采用{==稀疏索引==}，可以快速定位要消费的数据

3）{==顺序写==}磁盘

Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直{==追加到文件末端==}，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。

![image-20230207201755384](https://cos.gump.cloud/uPic/image-20230207201755384.png)

4）页缓存 + 零拷贝技术

![image-20230207201819094](https://cos.gump.cloud/uPic/image-20230207201819094.png)

| 参数                        | 描述                                                         |
| --------------------------- | ------------------------------------------------------------ |
| log.flush.interval.messages | 强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。 |
| log.flush.interval.ms       | 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。 |
