# 第十章 端到端一致性

> 端到端：上游设备 :arrow_right: Flink程序 :arrow_right: 下游设备

## 状态一致性分类

- AT-MOST-ONCE（最多一次）
  - 当任务故障时，最简单的做法是什么都不干，既不恢复丢失的状态，也不重播丢失的数据。at-most-once语义的含义是最多处理一次事件。例如：Socket 数据源，不提供任何一致性保障
- AT-LEAST-ONCE（至少一次）
  - 在大多数的真实应用场景，我们希望不丢失事件。这种类型的保障称为 at-least-once，意思是所有的事件都得到了处理，而一些事件还可能被处理多次。例如：print 算子。
- EXACTLY-ONCE（精确一次）
  - 恰好处理一次是最严格的保证，也是最难实现的。恰好处理一次语义不仅仅意味着没有事件丢失，还意味着针对每一个数据，内部状态仅仅更新一次。

## 端到端状态一致性

- 目前我们看到的一致性保证都是由流处理器实现的，也就是说都是在Flink流处理器内部保证的；而在真实应用中，流处理应用除了流处理器以外还包含了数据源（例如 Kafka）和输出到持久化系统。
- 端到端的一致性保证，意味着结果的正确性贯穿了整个流处理应用的始终；每一个组件都保证了它自己的一致性。
- 整个端到端的一致性级别取决于所有组件中一致性最弱的组件。

## 端到端EXACTLY-ONCE一致性保障

- 内部保证— checkpoint（分布式异步快照算法）
- Source 端—可重设数据的读取位置（Kafka，FileSystem）
  - 需要实现 `CheckpointedFunction` 接口。
- Sink端—从故障恢复时，数据不会重复写入外部系统（精准一次写入）
  - 幂等写入
  - 事务写入：需要实现 `TwoPhaseCommitSinkFunction` 接口。

## 幂等写入

所谓幂等操作，是说一个操作，可以重复执行很多次，但只导致一次结果更改，也就是说，后面再重复执行就不起作用了。

## 事务写入

- 事务（Transaction）  
  - 应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所作的所有更改都会被撤消（ACID）
  - 具有原子性：一个事务中的一系列的操作要么全部成功，要么一个都不做
- 实现思想：每一个检查点对应一个事务，输出的数据先缓存在事务中（不落盘），等到检查点保存真正完成的时候，才把所有要输出的结果从缓存中写入 Sink 系统中（落盘）。
- 实现方式
  - 两阶段提交（Two Phase Commit，2PC）

## 两阶段提交

- 对于每个检查点，Sink 任务会启动一个事务（下游设备的事务，比如 MySQL，Kakfa，如果下游设备不支持事务，那么必须自己实现一个事务）

  - {==预提交阶段==}：将要输出的数据写入（缓存）到外部 Sink 系统的事务中，但不正式提交它们，也就是先将要输出的数据缓存在下游设备的事务中。

    - ```sql
      begin transaction
        insert into ... // 预提交
        insert into ... // 预提交
      出现故障rollback()
      ```

  - {==正式提交==}：当 Sink 算子接收到检查点完成（所有的并行子任务都完成了快照的保存操作，作业管理器会向所有的并行子任务广播一条检查点完成的通知）的通知时，它才正式提交下游设备的事务，实现结果的真正写入。

    - ```sql
      ...
      ...
      commit // 正式提交
      ```

## 总结

|                  | 不可重置的源（Socket） | 可重置的源（Kafka） |
| ---------------- | ---------------------- | ------------------- |
| any sink         | at-most-once           | at-least-once       |
| {==幂等性sink==} | at-most-once           | ==exactly-once==    |
| 预写式日志sink   | at-most-once           | at-least-once       |
| {==两阶段提交==} | at-most-once           | ==exactly-once==    |

## Kafka :arrow_right: Flink :arrow_right: Kafka端到端一致性

- 内部—利用检查点机制，把状态存盘（HDFS），发生故障的时候可以恢复，保证内部的状态一致性。
- source—FlinkKafkaConsumer 作为 source，可以将刚消费完的偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性。
- sink—FlinkKafkaProducer 作为 sink。

### 两阶段提交步骤

1. 数据流的第一条数据来了之后，开启一个下游 Kafka 的事务（对应了第一个检查点），输出数据正常写入 Kafka 分区日志但标记为未提交，这就是“预提交”。
2. 作业管理器触发保存检查点的操作，检查点分界线从 Source 开始向下传递，遇到检查点分界线的算子将状态存入状态后端，并通知作业管理器。
3. Sink连接器收到检查点分界线，保存 Sink 的当前状态，存入检查点文件中，通知作业管理器，并开启下一阶段的事务，用于提交下个检查点的数据。
4. 作业管理器收到所有任务的通知，向所有的并行子任务广播确认信息，表示检查点完成。
5. Sink任务收到作业管理器的确认信息，正式提交这段时间的数据，将标记为未提交的分区标记为已提交，这就是“正式提交”。
6. 正式提交的数据可以正常消费了。

