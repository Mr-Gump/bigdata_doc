# 第3章 Flume进阶

## 3.1 Flume事务

![image-20230305103324507](https://cos.gump.cloud/uPic/image-20230305103324507.png)

## **3.2** **Flume** **Agent内部原理**

![image-20230305103605001](https://cos.gump.cloud/uPic/image-20230305103605001.png)

组件介绍：

**1）ChannelSelector**

ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型，分别是 {++Replicating++}（复制）和 {++Multiplexing++}（多路复用）。

ReplicatingSelector 会将同一个 Event 发往所有的 Channel，Multiplexing 会根据相应的原则，将不同的 Event 发往不同的 Channel。

**2）SinkProcessor**

SinkProcessor 共有三种类型，分别是 {++DefaultSinkProcessor++}(默认 1 对 1)、{++LoadBalancingSinkProcessor++} (负载均衡)和 {++FailoverSinkProcessor++}(故障转移)

DefaultSinkProcessor 对应的是单个的 Sink，LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 Sink Group，

LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。

## 3.3 Flume企业开发案例

### 3.3.1 复制案例

**1）案例需求**

使用 Flume-1 监控文件变动，Flume-1 将变动内容传递给 Flume-2，Flume-2 负责存储到 HDFS。同时 Flume-1 将变动内容传递给 Flume-3，Flume-3 负责输出到 Local FileSystem。

**2）需求分析**

![image-20230305104112653](https://cos.gump.cloud/uPic/image-20230305104112653.png)

**3）实现步骤**

（1）准备工作

在 /opt/module/flume/conf 目录下创建 group1 文件夹。

```shell
mkdir group1/
```

在 /opt/module/flume/ 目录下创建 flume3datas 文件夹。

```shell
mkdir flume3datas
```

（2）创建 flume1.conf

配置 1 个接收日志文件的 source 和两个 channel、两个 sink，分别输送给 flume2 和 flume3。

①编辑配置文件

```shell
vim flume1.conf
```

②添加如下内容

```conf title="flume1.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2

# Describe/configure the source
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1 f2
a1.sources.r1.filegroups.f1 = /opt/module/flume/files1/.*file.*
a1.sources.r1.filegroups.f2 = /opt/module/flume/files2/.*log.*
a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json


# 将数据流复制给所有channel 默认参数可以不写
a1.sources.r1.selector.type = replicating


# Describe the sink
# sink端的avro是一个数据发送者
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102 
a1.sinks.k1.port = 4141

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102
a1.sinks.k2.port = 4142

# Describe the channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2
```

（3）创建 flume2.conf

配置上级 Flume 输出的 Source，输出是到 HDFS 的 Sink。

①编辑配置文件

```shell
vim flume2.conf
```

②添加如下内容

```conf title="flume2.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source

a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop102
a1.sources.r1.port = 4141


# Describe the sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://hadoop102:8020/flume1/%Y%m%d/%H
# 文件的前缀
a1.sinks.k1.hdfs.filePrefix = log-

#多久生成一个新的文件
a1.sinks.k1.hdfs.rollInterval = 30
#设置每个文件的滚动大小大概是128M
a1.sinks.k1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a1.sinks.k1.hdfs.rollCount = 0
# 使用本地的时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true

#设置文件类型 分为二进制文件SequenceFile和文本文件DataStream(不能压缩) 和CompressedStream(可以压缩)
a1.sinks.k1.hdfs.fileType = DataStream


# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

（4）创建 flume3.conf

配置上级 Flume 输出的 Source，输出是到本地目录的 Sink。

①编辑配置文件

```shell
vim flume3.conf
```

②添加如下内容

```conf title="flume3.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source

a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop102
a1.sources.r1.port = 4142


# Describe the sink
a1.sinks.k1.type = file_roll
a1.sinks.k1.sink.directory = /opt/module/flume/flume3datas


# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

!!! info "提示" 

    输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录。

（5）启动 Hadoop

```shell
sbin/start-dfs.sh
sbin/start-yarn.sh
```

（6）执行配置文件

分别启动对应的 flume 进程：flume1，flume2，flume3。

```shell
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group1/flume3.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group1/flume2.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group1/flume1.conf
```

（7）向监控的文件传入数据

```shell
echo hello >> file1.txt
```

（8）检查 HDFS 上数据

![image-20230305105051251](https://cos.gump.cloud/uPic/image-20230305105051251.png)

（8）检查 /opt/module/datas/flume3 目录中数据

```shell
ll

总用量 8
-rw-rw-r--. 1 atguigu atguigu 5942 5月  22 00:09 1526918887550-3
```

### 3.3.2 多路复用及拦截器的使用

**1）案例需求**

使用 Flume 采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不同的分析系统。

**2）需求分析**

在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到 Flume 的channel selecter 中的 Multiplexing 结构，{==Multiplexing 的原理是，根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel 中，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值==}。

在该案例中，我们以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义 interceptor 区分数字和字母，将其分别发往不同的分析系统（Channel）。

![image-20230305105339960](https://cos.gump.cloud/uPic/image-20230305105339960.png)

**3）实现步骤**

（1）创建一个 maven 项目，并引入以下依赖。

```xml title="pom.xml"
<dependencies>
	<dependency>
		<groupId>org.apache.flume</groupId>
		<artifactId>flume-ng-core</artifactId>
		<version>1.9.0</version>
	</dependency>
</dependencies>
```

（2）定义 CustomInterceptor 类并实现 Interceptor 接口。

```java
package com.atguigu.flume;

import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.interceptor.Interceptor;

import java.util.List;
import java.util.Map;

/**
 * @author yhm
 * @create 2021-07-28 15:14
 *
 * 1. 实现interceptor接口
 * 2. 实现接口的4个方法
 * 3. 实现一个静态内部类创建拦截器
 */
public class MyInterceptor implements Interceptor {
    /**
     * 初始化方法
     */
    @Override
    public void initialize() {

    }

    /**
     * 处理单条event
     * @param event
     * @return
     */
    @Override
    public Event intercept(Event event) {
        // 需要配合channel选择器使用  向headers当中put对应的参数
        // 根据传入的数据 首位是数字还是字母  判断他是不同类型的日志
        byte[] body = event.getBody();
        byte b = body[0];
        Map<String, String> headers = event.getHeaders();

        if (b >= '0' && b <= '9'){
            // b为数字
            headers.put("type","number");
        }else if((b >= 'a' && b <= 'z') || (b >= 'A' && b <= 'Z')){
            // b 为字母
            headers.put("type","letter");
        }

        // 可以不需要在写放回headers
        event.setHeaders(headers);

        return event;
    }

    /**
     * 处理多条evebt
     * @param events
     * @return
     */
    @Override
    public List<Event> intercept(List<Event> events) {
        for (Event event : events) {
            intercept(event);
        }
        return events;
    }

    /**
     * close方法
     */
    @Override
    public void close() {

    }

    // 静态内部类
    public static class MyBuilder implements Builder{

        /**
         * 创建拦截器
         * @return
         */
        @Override
        public Interceptor build() {
            return new MyInterceptor();
        }

        /**
         * 配置方法
         * @param context
         */
        @Override
        public void configure(Context context) {

        }
    }
}
```

代码完成后，在 Idea 打成 jar 上传到 hadoop102 的 /opt/module/flume/lib 目录下。

（3）编辑 flume 配置文件

创建新文件 conf/group2/flume1，创建新文件 conf/group2/flume2,创建新文件 conf/group2/flume3。
为 Flume1 配置 1 个 netcat source，1 个 sink group（2 个 avro sink），并配置相应的 ChannelSelector 和 interceptor。

```conf
# Name the components on this agent
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444


a1.sources.r1.selector.type = multiplexing
# 使用headers中的哪些参数
a1.sources.r1.selector.header = type
a1.sources.r1.selector.mapping.number = c1
a1.sources.r1.selector.mapping.letter = c2

# a1.sources.r1.selector.default = c4

# 拦截器配置
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.atguigu.flume.MyInterceptor$MyBuilder

# Describe the sink

a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102
a1.sinks.k1.port = 4141

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102
a1.sinks.k2.port = 4142

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2
```

为 Flume2 配置一个 avro source 和一个 logger sink。

```conf
a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop102
a1.sources.r1.port = 4141

a1.sinks.k1.type = logger

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.k1.channel = c1
a1.sources.r1.channels = c1
```

为 Flume3 配置一个 avro source 和一个 logger sink。

```conf
a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop102
a1.sources.r1.port = 4142

a1.sinks.k1.type = logger


a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.k1.channel = c1
a1.sources.r1.channels = c1
```

（4）分别启动 flume1，flume2 和 flume3。

```shell
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group2/flume3.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group2/flume2.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group2/flume1.conf
```

（5）在 hadoop102 使用 netcat 向 localhost:44444 发送字母和数字。

（6）观察 flume2 和 flume3 打印的日志。

### 3.3.3 聚合案例

**1）案例需求：**

hadoop102 上的 Flume-1 监控文件 /opt/module/flume/files1/.*file.*，

hadoop103 上的 Flume-2 监控某一个端口的数据流，

Flume-1 与 Flume-2 将数据发送给 hadoop104 上的 Flume-3，Flume-3 将最终数据打印到控制台。

**2）需求分析**

![image-20230305110009841](https://cos.gump.cloud/uPic/image-20230305110009841.png)

**3）实现步骤：**

（1）准备工作

①分发 Flume

```shell
xsync flume
```

②在 hadoop102、hadoop103 以及 hadoop104 的 /opt/module/flume/conf 目录下创建一个 group3 文件夹。

```shell
mkdir group3
```

（2）创建 flume1.conf

配置 Source 用于监控本地文件，配置 Sink 输出数据到下一级 Flume。

①在 hadoop102 上编辑配置文件

```shell
vim flume1.conf 
```

②添加如下内容

```conf title="flume1.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1 f2
a1.sources.r1.filegroups.f1 = /opt/module/flume/files1/.*file.*
a1.sources.r1.filegroups.f2 = /opt/module/flume/files2/.*log.*
a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json


# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop104
a1.sinks.k1.port = 4141


# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

（3）创建 flume2.conf

配置 Source 监控端口 44444 数据流，配置 Sink 数据到下一级 Flume：

①在 hadoop103 上编辑配置文件

```shell
vim flume2.conf
```

②添加如下内容

```conf title="flume2.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop104
a1.sinks.k1.port = 4141

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

（4）创建 flume3.conf

配置 source 用于接收 flume1 与 flume2 发送过来的数据流，最终合并后 sink 到控制台。

①在 hadoop104 上编辑配置文件

```shell
vim flume3.conf
```

②添加如下内容

```conf title="flume3.conf"
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source

a1.sources.r1.type = avro
a1.sources.r1.bind = hadoop104
a1.sources.r1.port = 4141


# Describe the sink
a1.sinks.k1.type = logger


# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

（5）执行配置文件

分别开启对应配置文件：flume1.conf，flume2.conf，flume3.conf。

```shell
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group3/flume1.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group3/flume2.conf
bin/flume-ng agent --conf conf/ --name a1 --conf-file conf/group3/flume3.conf
```

（6）在 hadoop102 上向 /opt/module/flume 目录下的 group.log 追加内容

```shell
echo 'hello' > file1
```

（7）在 hadoop103 上向 44444 端口发送数据

```shell
nc hadoop103 44444
```

（8）检查 hadoop104 上数据

![image-20230305110743893](https://cos.gump.cloud/uPic/image-20230305110743893.png)
