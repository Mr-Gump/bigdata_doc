# 第4章 Maxwell使用

## 4.1 启动Kafka集群

若 Maxwell 发送数据的目的地为 Kafka 集群，则需要先确保 Kafka 集群为启动状态。

## 4.2 Maxwell启停 

1）启动 Maxwell

```shell
/opt/module/maxwell/bin/maxwell --config /opt/module/maxwell/config.properties --daemon
```

2）停止 Maxwell

```shell
 ps -ef | grep maxwell | grep -v grep | grep maxwell | awk '{print $2}' | xargs kill -9
```

3）Maxwell 启停脚本

（1）创建并编辑 Maxwell 启停脚本

```sh title="mxw.sh"
#!/bin/bash

MAXWELL_HOME=/opt/module/maxwell

status_maxwell(){
    result=`ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | wc -l`
    return $result
}


start_maxwell(){
    status_maxwell
    if [[ $? -lt 1 ]]; then
        echo "启动Maxwell"
        $MAXWELL_HOME/bin/maxwell --config $MAXWELL_HOME/config.properties --daemon
    else
        echo "Maxwell正在运行"
    fi
}


stop_maxwell(){
    status_maxwell
    if [[ $? -gt 0 ]]; then
        echo "停止Maxwell"
        ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | awk '{print $2}' | xargs kill -9
    else
        echo "Maxwell未在运行"
    fi
}


case $1 in
    start )
        start_maxwell
    ;;
    stop )
        stop_maxwell
    ;;
    restart )
       stop_maxwell
       start_maxwell
    ;;
esac
```

## 4.3 增量数据同步

1）启动 Kafka 消费者

```shell
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic maxwell
```

2）模拟生成数据

```shell
java -jar gmall2020-mock-db-2021-01-22.jar
```

3）观察 Kafka 消费者

```shell
{"database":"gmall","table":"comment_info","type":"insert","ts":1634023510,"xid":1653373,"xoffset":11998,"data":{"id":1447825655672463369,"user_id":289,"nick_name":null,"head_img":null,"sku_id":11,"spu_id":3,"order_id":18440,"appraise":"1204","comment_txt":"评论内容：12897688728191593794966121429786132276125164551411","create_time":"2020-06-16 15:25:09","operate_time":null}}
{"database":"gmall","table":"comment_info","type":"insert","ts":1634023510,"xid":1653373,"xoffset":11999,"data":{"id":1447825655672463370,"user_id":774,"nick_name":null,"head_img":null,"sku_id":25,"spu_id":8,"order_id":18441,"appraise":"1204","comment_txt":"评论内容：67552221621263422568447438734865327666683661982185","create_time":"2020-06-16 15:25:09","operate_time":null}}
```

## 4.4 历史数据全量同步

上一节，我们已经实现了使用 Maxwell 实时增量同步 MySQL 变更数据的功能。但有时只有增量数据是不够的，我们可能需要使用到 MySQL 数据库中从历史至今的一个完整的数据集。这就需要我们在进行增量同步之前，先进行一次历史数据的全量同步。这样就能保证得到一个完整的数据集。

## 4.5 提高并行度

如果要提高并行度，首先设置 kafka 的分区数 > 1,然后设置 `producer_partition_by` 属性
可选值 producer_partition_by=database|table|primary_key|random|column

| 配置项      | 说明     |
| ----------- | -------- |
| database    | 数据库名 |
| table       | 表名     |
| primary_key | 主键名   |
| random      | 随机     |
| column      | 列名     |

### 4.4.1 Maxwell-bootstrap

Maxwell 提供了 bootstrap 功能来进行历史数据的全量同步，命令如下：

```shell
/opt/module/maxwell/bin/maxwell-bootstrap --database gmall --table user_info --config /opt/module/maxwell/config.properties
```

### 4.4.2 boostrap数据格式

采用 bootstrap 方式同步的输出数据格式如下：

```json
{
    "database": "fooDB",
    "table": "barTable",
    "type": "bootstrap-start",
    "ts": 1450557744,
    "data": {}
}
{
    "database": "fooDB",
    "table": "barTable",
    "type": "bootstrap-insert",
    "ts": 1450557744,
    "data": {
        "txt": "hello"
    }
}
{
    "database": "fooDB",
    "table": "barTable",
    "type": "bootstrap-insert",
    "ts": 1450557744,
    "data": {
        "txt": "bootstrap!"
    }
}
{
    "database": "fooDB",
    "table": "barTable",
    "type": "bootstrap-complete",
    "ts": 1450557744,
    "data": {}
}
```

!!! info "注意事项"

    1）第一条 type 为 bootstrap-start 和最后一条 type 为 bootstrap-complete 的数据，是 bootstrap 开始和结束的标志，不包含数据，中间的 type 为 bootstrap-insert 的数据才包含数据。
    
    2）一次 bootstrap 输出的所有记录的 ts 都相同，为 bootstrap 开始的时间。

