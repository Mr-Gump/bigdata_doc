# 面一

## （1）自我介绍

## （2）做实时用 Flink SQL 还是 API

相关阅读：[:material-book:Flink 在字节跳动数据流的实践](https://xie.infoq.cn/article/fdf21431c62dfd34489f0791e)

相关视频: [:octicons-video-16:Flink Forward Asia 2021](https://developer.aliyun.com/special/ffa2021/live#live)

> 从文章和视频中可以看出，由于字节跳动特殊的业务场景，需要实时处理海量数据（主要是埋点数据），目前处于流处理的探索阶段，在字节跳动中，Flink 主要的作用是 ETL(Extract Transformation Load) ，从上游 MQ 消费埋点数据，处理后发送给下游的 MQ 实现分流，由于其业务面很广，需要经常变更需求，其研发了配置中心，在 Process 中可以从配置中心实时获取需求，灵活应对业务改变，其并没有大规模转向Flink SQL

做实时主要使用 Flink 提供的基本转换算子和底层 API，相比 Flink SQL ，Flink API 更加灵活，可以通过底层的 processFunction ，自定义定时器和数据处理逻辑，方便对具体业务进行调优。而 Flink SQL 正在发展阶段，支持的 SQL 语法并不完整，有些功能无法使用 Flink SQL 实现，并且调优相对困难。

## （3）Flink 反压，如何排查

[:link:官方文档](https://nightlies.apache.org/flink/flink-docs-master/zh/docs/ops/monitoring/back_pressure/)

Flink 反压是数据流出速度小于速度流入速度造成的，发生反压时，生产数据的速率比下游 task 消费数据的速率要快。 在工作流中数据记录是从上游向下游流动的（例如：从 Source 到 Sink）。反压沿着相反的方向传播，沿着数据流向上游传播。

Flink 在 Web UI 中提供反压的监控，作业图中可以通过颜色和指标查看当前的反压情况，反压是从下游向上游传递的，反压要从后往前排查，定位到最开始发生反压的任务，逐步向前排查问题

> 判断反压最直接的方式是使用Flink UI提供的反压检查功能，而不是通过指标判断。反压的存在会导致Source端数据发送至下游算子的速率下降，您可能会观察到sourceIdleTime周期性上升，currentFetchEventTime和currentEmitEventTimeLag不断增长。极限情况下（某些算子卡死）sourceIdleTime会持续上升。      ——阿里云 Flink 文档

## （4）算子链断链有哪些方式，从代码层面说

[:link:参考博客](https://blog.csdn.net/lw277232240/article/details/105927818)

算子链断链主要是不想让多个算子分配到一个 task slot 中，这样可能导致特定 task slot 压力过大。

在代码层面 Flink 算子链断链有四种方法：

1. 在需要断链的算子后使用 `.disableChaining()` 方法强行阻止算子合并
2. 在算子后使用 `.startNewChain()` 方法开启一条新算子链，与原来的算子链断开
3. 全局关闭算子链合并机制 `env.disableOperatorChaining()` 
4. 在每个算子后使用 `.slotSharingGroup("1")` 方法指定共享组，组号不同的算子不能共享任务插槽

## （5）在排查 Flink 问题的时候有没有关注过 Flink 的 metrics 比如 Flink 自带的 metrics

[:link:官方文档](https://nightlies.apache.org/flink/flink-docs-master/zh/docs/ops/metrics/)

[:material-book:阿里云Flink实时计算服务指标说明](https://help.aliyun.com/document_detail/405992.html)

使用 Flink metrics 可以在富函数中插入自定义指标，也可以使用系统预定义好指标，其中最重要的指标是

| 指标                                              | 详情                                                         |
| :------------------------------------------------ | :----------------------------------------------------------- |
| sourceIdleTime                                    | 该指标反映 Source 是否有闲置，如果该指标较大，说明您的数据在外部系统中的产生速率较低。 |
| currentFetchEventTimeLag和currentEmitEventTimeLag | 均反映了 Flink 当前处理的延迟，您可以通过两个指标的差值（即数据在 Source 中停留的时间）分析 Source 当前的处理能力。如果两个延迟非常接近，说明 Source 从外部系统中拉取数据的能力（网络 I/O、并发数）不足。如果两个延迟差值较大，说明 Source 的数据处理能力（数据解析、并发、反压）不足。 |
| pendingRecords                                    | 如果您使用的 Connector 汇报了 pendingRecords 指标，那么您可以通过该指标分析数据在外部系统的滞留数据量。 |

Flink metrics 还提供对其他多种指标的监控

- 输入/输出数据条数/数量
- 检查点
- 状态变量
- IO
- 水位线
- JM ( Job Master )
- TM (Task Manager)
- HBase命中率等

## （6）checkpoint的流程，说说理解

[:link:官方文档](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/dev/datastream/fault-tolerance/checkpointing/)

[:link:非对齐检查点参考博客](https://cloud.tencent.com/developer/article/2016019)

检查点机制是 Flink 中最重要的概念之一，检查点与状态变量配合使用记录系统某个时刻的状态信息，为 Flink 提供了容错性。检查点快照遵循分布式异步快照算法（Chandy-Lamport算法），Flink 会周期性在数据源注入 Barrier，Barrier 是一种特殊数据，当 Barrier 其到达检查点时，检查点将对当前状态进行快照，并上传到状态后端，当使用检查点对齐时，算子会暂停当前计算，并将数据存储在缓冲区中，等待所有的 Barrier 到达算子后再继续进行数据计算，若使用非对齐检查点，当算子的第一个 Barrier 到达时即开始计算，并不会阻塞计算，但是快照时需要保存非对齐部分的数据。当 Sink 算子完成快照后，JobManager 认为当前检查点快照完成，通知所有算子，若有算子快照超时或失败，则认为本次检查点快照失败。

## （7）端到端一致性，如果挂掉了怎么办

流处理的过程可以抽象为三端：输入端 -> 内部算子端 -> 输出端，所谓端到端一致性就是保证最终状态和处理结果的精准一致。流处理在保证端到端一致性中面临的最大问题是输入端的“一锤子买卖”，即在故障时数据源不具备数据重发的能力；以及输出端的“覆水难收”，即在故障恢复时可能导致故障前的部分数据发生重复。Flink 需要具备数据重放功能的数据源在输入端保证 **至少一次**，在故障发生时，系统通过检查点恢复到之前的状态，从上个检查点的偏移量进行数据重放。同时，Flink 在输出端通过幂等性/WAL/2PC保证**至多一次**，故障发生时，进行事务回滚或数据的 upsert 防止数据重复。从而，Flink 可以保证流处理系统端到端的一致性。

## （8）flink写hive是否能保证端到端一致性？怎么保证幂等写入，overwrite 不是会覆盖吗？不会丢数据吗？ 

Flink 写 Hive 能保证端到端一致性。由于流处理可能导致数据的更新，而 Hive 本身不支持 upsert 写入，而 insert overwrite 又会导致数据的覆盖，因此可以利用 Hive 提供的事务功能通过 2PC 保证数据的**至多一次**，当系统挂掉时，通过事务回滚的方式放置数据重复。

## （9）遇到的数据倾斜的场景和对应解决方案

数据倾斜可能发生在数据源、分组和开窗时。

数据源倾斜可能由于 Kafka 不同主题或同一主题的不同分区的数据量出现倾斜，可以通过 shuffle、rebalance 等重分区的方法对分配到每个子任务的数据进行重新分布。若是分组聚合导致的数据倾斜，可以通过预聚合的方式进行缓解。若是开窗导致的数据倾斜，可以通过为数据添加随机数，使用两步聚合的方式缓解数据倾斜。

## （10）场景题，字段：uid-用户id，vid-视频id，timestamp-时间戳，计算每个视频的uv，一个用户可以看多次视频，由于有热门视频，会有数据倾斜，怎么用flink应用程序实现，追问，细问加随机数怎么加，继续追问更复杂的场景状态怎么办。Split Distinct的底层原理是什么？

[:link:官方文档](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/dev/table/tuning/)

[:link:参考博客](https://blog.csdn.net/wangpei1949/article/details/105619361)

这个场景属于 uid 稀疏的场景，应该开启 Split Distinct 优化，原理是 Flink 会自动将 count distinct 处理为两次分组聚合，第一次使用 `MOD(HASH_CODE(uid), 1024)` 进行分组，将相同 uid 的数据发往同一个 subtask，在这样可以在相同的 subtask 里对数据进行聚合，大大避免了全局去重带来的 IO 和计算带来的时间开销。

## （11）补充：如果rocksDB放不开了怎么办，状态编程去重只能去掉3%左右，性能不太好，有没有更好的解决方案？ 

