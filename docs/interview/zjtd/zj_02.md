# 面2

## （1）怎么保证flink的一致性，两阶段提交，怎么保证数据不重复，最后解决了吗。

Flink 分别在 Source Transformation Sink 三端保证一致性，在 Source 端通过算子状态+检查点+可重放数据源保证端到端一致性，Transformation 通过检查点机制保证端到端一致性，Sink 端通过对支持事务的组件进行两阶段提交或支持幂等性写入的组件实现的

## （2）clickhouse 怎么保证幂等性

可以使用 ReplacingMergeTree 表引擎实现写入幂等性，但需要注意去重时机问题。

## （3）sink端的事务输出 输出到哪些组件

sink 端事务可以输出到任何支持事务的组件，例如 MySQL等支持事务的关系型数据库，以及支持事务的消息队列组件，例如 Kafka Pulsar，当下游组件不支持事务时，可以在 Flink 端手动维护事务

## （4）kafka和clickhouse各自的应用方向都是哪些

Kafka 定位是发布订阅模式的消息队列，Clickhouse 定位是 OLAP 数据库。Kafka 可以用在流量消峰，业务解耦和异步通信。Clickhouse 是列式存储的数据库，可以快速计算大量数据，主要用在即席查询和宽表查询

## （5）clickhouse为什么查询快

Clickhouse 采用列式存储结构，能快速处理聚合操作。ClickHouse 采用类 LSM Tree 的结构，数据写入后定期在后台 Compaction。通过类 LSM tree 的结构，ClickHouse 在数据导入时全部是顺序 append 写，写入后数据段不可更改，在后台 compaction 时也是多个段 merge sort 后顺序写回磁盘。顺序写的特性，充分利用了磁盘的吞吐能力，即便在 HDD 上也有着优异的写入性能。

## （6）clickhouse适应哪些业务场景

[:link:参考文章](https://zhuanlan.zhihu.com/p/358821358)

Clickhouse 可以用在大量数据的分析场景，例如，日志数据的分析，用户行为数据记录和分析工作等

## （7）一致性数据只是做到了数据的不丢失，怎么保证数据的准确性？

实际生产场景不仅需要考虑数据的一致性，一致性保证了不同节点访问数据的同步，除了一致性还需要保证数据不丢失不重复，以及数据的乱序问题。数据不丢失可以使用具有容错性的手段，例如高可用。数据不丢失可以使用幂等性或事务保证。数据乱序可以使用缓冲区，乱序流中水位线等机制保证。

