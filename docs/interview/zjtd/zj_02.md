# 面2

## （1）怎么保证flink的一致性，两阶段提交，怎么保证数据不重复，最后解决了吗。

Flink 分别在 Source Transformation Sink 三端保证一致性，在 Source 端通过算子状态+检查点+可重放数据源保证端到端一致性，Transformation 通过检查点机制保证端到端一致性，Sink 端通过对支持事务的组件进行两阶段提交或支持幂等性写入的组件实现的

## （2）clickhouse 怎么保证幂等性

可以使用 ReplacingMergeTree 表引擎实现写入幂等性，但需要注意去重时机问题。

## （3）sink端的事务输出 输出到哪些组件

sink 端事务可以输出到任何支持事务的组件，例如 MySQL等支持事务的关系型数据库，以及支持事务的消息队列组件，例如 Kafka Pulsar，当下游组件不支持事务时，可以在 Flink 端手动维护事务

## （4）kafka和clickhouse各自的应用方向都是哪些

Kafka 定位是发布订阅模式的消息队列，Clickhouse 定位是 OLAP 数据库。Kafka 可以用在流量消峰，业务解耦和异步通信。Clickhouse 是列式存储的数据库，可以快速计算大量数据，主要用在即席查询和宽表查询

## （5）clickhouse为什么查询快

Clickhouse 采用列式存储结构，能快速处理聚合操作。ClickHouse 采用类 LSM Tree 的结构，数据写入后定期在后台 Compaction。通过类 LSM tree 的结构，ClickHouse 在数据导入时全部是顺序 append 写，写入后数据段不可更改，在后台 compaction 时也是多个段 merge sort 后顺序写回磁盘。顺序写的特性，充分利用了磁盘的吞吐能力，即便在 HDD 上也有着优异的写入性能。

## （6）clickhouse适应哪些业务场景

[:link:参考文章](https://zhuanlan.zhihu.com/p/358821358)

Clickhouse 可以用在大量数据的分析场景，例如，日志数据的分析，用户行为数据记录和分析工作等

## （7）一致性数据只是做到了数据的不丢失，怎么保证数据的准确性？

准确性要保证数据既不多也不少，即端到端的一致性，通常使用事务保证数据不丢失，使用幂等性保证数据不重复。

## （8）你认为怎么去做才能保证数据的正确性

[:link:参考文档](https://help.aliyun.com/document_detail/73660.htm?spm=a2c4g.11186623.0.0.1f8c4b5fbkW74n#concept-zsz-44h-r2b)

保证数据正确性需要做好数据质量监控，在流处理中，需要处理好迟到数据，脏数据，异常数据，并及时进行数据校准

## （9）实时数据最后是都有谁去使用了

<figure markdown>
  ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu60AB6qnOnTTC16ESCc6ryJia1x6bzgnEqicIgqNkBZEnsqqflI3bo7icFCZEWBTkXia55uEYiblNopx6A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
  <figcaption>京东物流技术架构</figcaption>
</figure>

